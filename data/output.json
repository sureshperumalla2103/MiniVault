{
  "model": "test-model-v1",
  "prompt": "Hello world",
  "parameters": {
    "max_tokens": 100,
    "temperature": 0.7
  },
  "response": "Stub result"
}
